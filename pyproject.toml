[project]
name = "filechat"
version = "0.1.0"
description = "Add your description here"
readme = "README.md"
authors = [{ name = "Milos Svana", email = "milos.svana@mailfence.com" }]
requires-python = ">=3.12"
dependencies = [
  "einops>=0.8.1",
  "faiss-cpu>=1.11.0.post1",
  "mistralai>=1.9.3",
  "pydantic>=2.11.7",
  "sentence-transformers>=5.0.0",
  "textual>=5.3.0",
  "watchdog>=6.0.0",
]

[project.scripts]
filechat = "filechat:main"

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[project.optional-dependencies]
cpu = [
  "torch @ https://download.pytorch.org/whl/cpu/torch-2.7.1%2Bcpu-cp312-cp312-manylinux_2_28_x86_64.whl ; python_version == '3.12'",
  "torch @ https://download.pytorch.org/whl/cpu/torch-2.7.1%2Bcpu-cp313-cp313-manylinux_2_28_x86_64.whl ; python_version == '3.13'",
]
xpu = [
  "pytorch-triton-xpu @ https://download.pytorch.org/whl/pytorch_triton_xpu-3.3.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl ; python_version == '3.12'",
  "pytorch-triton-xpu @ https://download.pytorch.org/whl/pytorch_triton_xpu-3.3.1-cp313-cp313-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl ; python_version == '3.13'",
  "torch @ https://download.pytorch.org/whl/xpu/torch-2.7.1%2Bxpu-cp312-cp312-linux_x86_64.whl ; python_version == '3.12'",
  "torch @ https://download.pytorch.org/whl/xpu/torch-2.7.1%2Bxpu-cp313-cp313-linux_x86_64.whl ; python_version == '3.13'",
]
cuda = [
  "torch @ https://download.pytorch.org/whl/cu126/torch-2.7.1%2Bcu126-cp312-cp312-manylinux_2_28_x86_64.whl ; python_version == '3.12'",
  "torch @ https://download.pytorch.org/whl/cu126/torch-2.7.1%2Bcu126-cp313-cp313-manylinux_2_28_x86_64.whl ; python_version == '3.13'",
]

[tool.uv]
conflicts = [[{ extra = "cpu" }, { extra = "xpu" }, { extra = "cuda" }]]

[tool.uv.sources]

[[tool.uv.index]]
name = "pytorch-xpu"
url = "https://download.pytorch.org/whl/xpu"
explicit = true

[[tool.uv.index]]
name = "pytorch-cpu"
url = "https://download.pytorch.org/whl/cpu"
explicit = true

[[tool.uv.index]]
name = "pytorch-cuda"
url = "https://download.pytorch.org/whl/cu126"
explicit = true

[tool.black]
line-length = 100
preview = true
unstable = true
enable-unstable-feature = [
  "multiline_string_handling",
  "string_processing",
  "wrap_long_dict_values_in_parens",
]

[tool.hatch.metadata]
allow-direct-references = true

[dependency-groups]
dev = ["pytest>=8.4.1"]
